{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Enviroment.BaseTaggerEnv.environment import PosCorrectionEnv\n",
    "from ..Utils.dataset import (\n",
    "    brown_to_training_data,\n",
    "    get_brown_as_universal,\n",
    "    get_brown_sentences,\n",
    "    get_tag_list,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_brown_as_universal()\n",
    "# sents = get_brown_sentences()\n",
    "print(dataset[0:10])\n",
    "# print(f\"Number of tagged sentences: {len(dataset)}\")\n",
    "# print(sents[0:10])\n",
    "\n",
    "tag_list = get_tag_list()\n",
    "print(f\"Tag list: {tag_list}, Number of tags: {len(tag_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1494a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Dataset Setup ---\n",
    "# Format: (Sentence, [List of Universal Tags])\n",
    "training_data = brown_to_training_data(\n",
    "    [dataset[i] for i in range(1000)]\n",
    ")  # Using first 1000 sentences\n",
    "\n",
    "# --- 2. Train and Save Model using Utils ---\n",
    "from Algorithms.Utils.model_training import train_pos_tagger\n",
    "\n",
    "# This function handles tokenization, dataset creation, training, and saving\n",
    "train_pos_tagger(training_data, tag_list, output_dir=\"./pos_tagger_model\", epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Registration ---\n",
    "gym.register(\n",
    "    id=\"gymnasium_env/PosCorrection-v0\",\n",
    "    entry_point=PosCorrectionEnv,\n",
    "    kwargs={\n",
    "        \"dataset\": training_data,\n",
    "        \"nlp_model\": \"en_core_web_sm\",\n",
    "    },  # Pass dataset to constructor\n",
    ")\n",
    "\n",
    "# --- 3. Create and Test ---\n",
    "env = gym.make(\"gymnasium_env/PosCorrection-v0\")\n",
    "\n",
    "# def\n",
    "\n",
    "obs, info = env.reset(seed=42)\n",
    "\n",
    "print(f\"Start Word: '{info['word']}' | Base Tag: {info['base_tag']}\")\n",
    "print(f\"Observation Keys: {obs.keys()}\")\n",
    "\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "print(\"\\n--- Starting Episode ---\")\n",
    "while not done:\n",
    "    # Random Agent for demonstration\n",
    "    # action = env.action_space.sample()\n",
    "    action = 0  # Always KEEP\n",
    "\n",
    "    # Execute Step\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    action_name = [\"KEEP\", \"SHIFT\", \"DICT\"][action]\n",
    "    word = info.get(\"word\", \"END\")\n",
    "\n",
    "    print(f\"Action: {action_name: <5} | Word: {word: <10} | Reward: {reward:.1f}\")\n",
    "\n",
    "    total_reward += reward\n",
    "    done = terminated or truncated\n",
    "\n",
    "print(f\"Episode Finished. Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b368e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example: Loading and Using the Saved Model with Utils ---\n",
    "from Algorithms.Utils.model_inference import PosTaggerInference\n",
    "\n",
    "# 1. Initialize the inference class\n",
    "saved_model_path = \"./pos_tagger_model\"\n",
    "inference = PosTaggerInference(saved_model_path, tag_list)\n",
    "\n",
    "# 2. Predict for a sentence\n",
    "text = \"Reinforcement learning is fascinating.\"\n",
    "results = inference.predict(text)\n",
    "\n",
    "# 3. Display\n",
    "print(f\"Input: {text}\")\n",
    "for token, tag in results:\n",
    "    print(f\"{token:<15} -> {tag}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
